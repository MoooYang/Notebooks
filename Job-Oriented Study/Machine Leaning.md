Tags

------

[^x]:Unfinished

# SVM[^x]

------

Requirement: whiteboard derivation



# Logistic Regression [^x]

------

Requirement: whiteboard derivation 

# Q&A

------

## Matrix



### What is Manhattan Distance ?

$|x_{1}-x_{2}|+|y_{1}-y_{2}|$



### What is overfitting and how to solve it?

Overfitting refers to a model that models the training data too well(the model is too complicated for the data).

Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impact the performance of the model on new data.

**solution**:

1. Cross validation [^x]
2. Regularization[^x]
3. Normalization [^x]
4. Dropout[^x]
5. Early stopping[^x]







## Model

------

### Why Logistic Regression is better than Linear Regression?[^x]



### How to parallel Logistic Regression?[^x]



### Relation and differences between LR and SVM?



## Framework

------

### TensorFlow computation graph?[^x]



# Resources

------

## Courses

 [Stanford CS229 Andrew Ng](https://see.stanford.edu/Course/CS229/)

## Books

1.  [机器学习周志华.pdf](Resources/机器学习周志华.pdf)  [南瓜书.git](https://github.com/datawhalechina/pumpkin-book)
2.  [统计学习方法.pdf](Resources/统计学习方法.pdf) 
3. 

